{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSU Worker (Kaggle)\n",
        "\n",
        "Run all: sets up GPU wheels and launches the watcher. Uses Kaggle's /kaggle/working as the DSU root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-click venv + CUDA-correct installs (Kaggle)\n",
        "import os, sys, subprocess, pathlib, re\n",
        "BASE = pathlib.Path('/kaggle/working/M4L-Demucs')\n",
        "VENV = BASE / '.venv'\n",
        "PY = VENV / 'bin' / 'python'\n",
        "BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Kaggle bootstrap. BASE=', BASE)\n",
        "print(subprocess.getoutput('nvidia-smi'))\n",
        "\n",
        "# Create isolated venv (once)\n",
        "if not VENV.exists():\n",
        "    subprocess.check_call([sys.executable, '-m', 'venv', str(VENV)])\n",
        "    subprocess.check_call([str(PY), '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'])\n",
        "\n",
        "# Detect CUDA and choose torch index/spec\n",
        "smi = subprocess.getoutput('nvidia-smi')\n",
        "m = re.search(r'CUDA Version:\\s*([0-9.]+)', smi)\n",
        "if not m:\n",
        "    raise RuntimeError('GPU not detected. In Kaggle: Settings → Accelerator → GPU, then Run all.')\n",
        "ver = m.group(1)\n",
        "if ver.startswith('12.6'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "elif ver.startswith('12.4'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu124','2.5.1','2.5.1','https://download.pytorch.org/whl/cu124')\n",
        "elif ver.startswith('12.'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "elif ver.startswith('11.8'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu118','2.1.2','2.1.2','https://download.pytorch.org/whl/cu118')\n",
        "else:\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "\n",
        "print('CUDA flavor:', fl)\n",
        "\n",
        "# Torch/torchaudio strictly from CUDA index inside venv\n",
        "subprocess.check_call([str(PY), '-m', 'pip', 'install', '--extra-index-url', idx,\n",
        "                       f'torch=={torch_ver}+{fl}', f'torchaudio=={ta_ver}+{fl}'])\n",
        "\n",
        "# Demucs and deps inside venv (no global bleed)\n",
        "subprocess.check_call([str(PY), '-m', 'pip', 'install', 'demucs==4.0.1', 'torchcodec', 'ffmpeg-python', 'numpy==2.3.4'])\n",
        "\n",
        "# Verify\n",
        "subprocess.run([str(PY), '-c', \"import torch, demucs; print('Boot OK.', 'torch', torch.__version__, 'cuda', torch.cuda.is_available(), 'demucs', demucs.__version__)\"] , check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch watcher (Kaggle)\n",
        "import urllib.request, pathlib, os\n",
        "BASE = pathlib.Path(os.environ.get('DSU_ROOT','/kaggle/working/M4L-Demucs'))\n",
        "w = BASE/'colab_watcher.py'\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/VSTOPIA/Doctor-Sample-Unit-DSU/main/colab_watcher.py', w)\n",
        "print('Watcher saved to', w)\n",
        "!python -u - <<'PY'\n",
        "import os\n",
        "os.environ['DSU_ROOT'] = '/kaggle/working/M4L-Demucs'\n",
        "os.environ['DSU_REMOTE_JOBS_URL'] = 'https://raw.githubusercontent.com/VSTOPIA/Doctor-Sample-Unit-DSU/main/remote_jobs.jsonl'\n",
        "print('DSU_ROOT=', os.environ['DSU_ROOT'])\n",
        "print('DSU_REMOTE_JOBS_URL=', os.environ['DSU_REMOTE_JOBS_URL'])\n",
        "PY\n",
        "\n",
        "# Run watcher with venv python (from cell 1)\n",
        "import subprocess\n",
        "subprocess.call([str(PY), str(w)])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
