{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DSU fast bootstrap: cache wheels + site-packages (Kaggle/Colab)\n",
        "import os, sys, subprocess, pathlib, json, shutil, re\n",
        "\n",
        "ENV = \"kaggle\" if \"KAGGLE_URL_BASE\" in os.environ else (\"colab\" if os.environ.get(\"COLAB_GPU\") else \"local\")\n",
        "print(\"DSU Worker backend:\", ENV)\n",
        "\n",
        "# Persistent locations\n",
        "if ENV == \"kaggle\":\n",
        "    DATASET = pathlib.Path(\"/kaggle/input/dsu-cache\")\n",
        "    BASE = pathlib.Path(\"/kaggle/working/DSU_cache\")  # persists with Files on\n",
        "else:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/content/drive\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    DATASET = pathlib.Path(\"/not/attached\")\n",
        "    BASE = pathlib.Path(\"/content/drive/MyDrive/DSU_cache\")\n",
        "\n",
        "WHEELS = BASE / \"wheels\"\n",
        "SITEPKG = BASE / \"site-packages\"\n",
        "MODELS = BASE / \"models\"\n",
        "for p in (WHEELS, SITEPKG, MODELS): p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Model/checkpoint cache (Demucs)\n",
        "os.environ[\"XDG_CACHE_HOME\"] = str(MODELS)\n",
        "os.environ[\"DEMUCS_CACHE\"] = str(MODELS)\n",
        "os.environ[\"HF_HOME\"] = str(MODELS)\n",
        "\n",
        "# Version pins\n",
        "TORCH_VER = \"2.8.0\"\n",
        "AUDIO_VER = \"2.8.0\"\n",
        "DEMUCS_VER = \"4.0.1\"\n",
        "\n",
        "# Detect CUDA flavor\n",
        "smi = subprocess.getoutput('nvidia-smi')\n",
        "m = re.search(r'CUDA Version:\\s*([0-9.]+)', smi)\n",
        "flavor_order = []\n",
        "if m:\n",
        "    ver = m.group(1)\n",
        "    if ver.startswith('12.6'): flavor_order = ['cu126','cu124','cu121','cu118']\n",
        "    elif ver.startswith('12.4'): flavor_order = ['cu124','cu126','cu121','cu118']\n",
        "    elif ver.startswith('12.'): flavor_order = ['cu126','cu121','cu118']\n",
        "    elif ver.startswith('11.8'): flavor_order = ['cu118','cu121']\n",
        "else:\n",
        "    flavor_order = ['cu126','cu121','cu118']\n",
        "print('CUDA flavors preference:', flavor_order)\n",
        "\n",
        "# Helpers\n",
        "def install_from_wheels(wdir: pathlib.Path):\n",
        "    print('Installing from cached wheels:', wdir)\n",
        "    subprocess.check_call([\n",
        "        sys.executable, '-m', 'pip', 'install', '--no-index', '--find-links', str(wdir),\n",
        "        '--upgrade', '--target', str(SITEPKG),\n",
        "        'torch', 'torchaudio', f'demucs=={DEMUCS_VER}', 'ffmpeg-python', 'numpy'\n",
        "    ])\n",
        "\n",
        "# Prefer Kaggle Dataset wheels for instant cold-start\n",
        "used_dataset = False\n",
        "if DATASET.exists():\n",
        "    for fl in flavor_order:\n",
        "        wd = DATASET / f'wheels_{fl}'\n",
        "        if wd.exists():\n",
        "            try:\n",
        "                install_from_wheels(wd)\n",
        "                used_dataset = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print('Dataset wheels failed for', fl, e)\n",
        "    if not used_dataset and (DATASET / 'wheels').exists():\n",
        "        try:\n",
        "            install_from_wheels(DATASET / 'wheels')\n",
        "            used_dataset = True\n",
        "        except Exception as e:\n",
        "            print('Dataset generic wheels failed', e)\n",
        "    # Optional copy models\n",
        "    if (DATASET / 'models').exists():\n",
        "        for item in (DATASET / 'models').iterdir():\n",
        "            dst = MODELS / item.name\n",
        "            if not dst.exists():\n",
        "                if item.is_dir(): shutil.copytree(item, dst)\n",
        "                else: shutil.copy2(item, dst)\n",
        "\n",
        "# Drive-only cache: download once into WHEELS and reuse\n",
        "marker = SITEPKG / f\".ok_torch{TORCH_VER}_demucs{DEMUCS_VER}\"\n",
        "if not used_dataset and not marker.exists():\n",
        "    def download_wheels(cuda_flavor: str):\n",
        "        idx = f\"https://download.pytorch.org/whl/{cuda_flavor}\"\n",
        "        print('Downloading wheels', cuda_flavor, 'to', WHEELS)\n",
        "        return subprocess.call([\n",
        "            'pip','download','-d',str(WHEELS),'--prefer-binary','--only-binary=:all:',\n",
        "            '--extra-index-url', idx,\n",
        "            f'torch=={TORCH_VER}+{cuda_flavor}', f'torchaudio=={AUDIO_VER}+{cuda_flavor}',\n",
        "            f'demucs=={DEMUCS_VER}','ffmpeg-python','numpy'\n",
        "        ])\n",
        "    ok = False\n",
        "    for fl in flavor_order:\n",
        "        if download_wheels(fl) == 0:\n",
        "            try:\n",
        "                install_from_wheels(WHEELS)\n",
        "                ok = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print('Install from wheels failed for', fl, e)\n",
        "                continue\n",
        "    if not ok:\n",
        "        raise RuntimeError('Failed to fetch/install Torch/Demucs wheels for available CUDA flavors')\n",
        "    marker.write_text('ok')\n",
        "\n",
        "# Ensure our site-packages is importable\n",
        "if str(SITEPKG) not in sys.path:\n",
        "    sys.path.insert(0, str(SITEPKG))\n",
        "\n",
        "# Verify and persist runtime mode for watcher runner\n",
        "import torch, demucs\n",
        "print('Boot OK | torch', torch.__version__, '| cuda', torch.cuda.is_available(), '| demucs', demucs.__version__)\n",
        "BASE_RUN = pathlib.Path('/kaggle/working/M4L-Demucs') if ENV=='kaggle' else pathlib.Path('/content/drive/MyDrive/M4L-Demucs')\n",
        "BASE_RUN.mkdir(parents=True, exist_ok=True)\n",
        "PMARK = BASE_RUN / 'PY_MODE.json'\n",
        "PMARK.write_text(json.dumps({'mode':'target','py':sys.executable,'site':str(SITEPKG),'base':str(BASE_RUN),'fast':True}))\n",
        "print('PY_MODE written:', PMARK)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSU Worker (Kaggle)\n",
        "\n",
        "Run all: sets up GPU wheels and launches the watcher. Uses Kaggle's /kaggle/working as the DSU root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-click venv (preferred) or virtualenv, else target-site + CUDA-correct installs (Kaggle)\n",
        "import os, sys, subprocess, pathlib, re, json\n",
        "BASE = pathlib.Path('/kaggle/working/M4L-Demucs')\n",
        "VENV = BASE / '.venv'\n",
        "PY = VENV / 'bin' / 'python'\n",
        "SITE_TARGET = BASE / '.py-site' / 'site-packages'\n",
        "PMARK = BASE / 'PY_MODE.json'\n",
        "BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Kaggle bootstrap. BASE=', BASE)\n",
        "print(subprocess.getoutput('nvidia-smi'))\n",
        "\n",
        "mode = 'venv'\n",
        "py_exec = None\n",
        "site_dir = ''\n",
        "\n",
        "# Try Python venv first (with --copies to avoid symlink issues)\n",
        "try:\n",
        "    if not VENV.exists():\n",
        "        subprocess.check_call([sys.executable, '-m', 'venv', '--copies', str(VENV)])\n",
        "        subprocess.check_call([str(PY), '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'])\n",
        "    py_exec = str(PY)\n",
        "except Exception as e1:\n",
        "    print('python -m venv failed:', e1)\n",
        "    # Try virtualenv (often more robust on hosted envs)\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--user', 'virtualenv'])\n",
        "        subprocess.check_call([sys.executable, '-m', 'virtualenv', '--download', str(VENV)])\n",
        "        py_exec = str(PY)\n",
        "        mode = 'venv'\n",
        "        print('virtualenv succeeded')\n",
        "    except Exception as e2:\n",
        "        print('virtualenv failed, using --target site-packages fallback:', e2)\n",
        "        mode = 'target'\n",
        "        site_dir = str(SITE_TARGET)\n",
        "        os.makedirs(site_dir, exist_ok=True)\n",
        "        py_exec = sys.executable\n",
        "\n",
        "# Detect CUDA and choose torch index/spec\n",
        "smi = subprocess.getoutput('nvidia-smi')\n",
        "m = re.search(r'CUDA Version:\\s*([0-9.]+)', smi)\n",
        "if not m:\n",
        "    raise RuntimeError('GPU not detected. In Kaggle: Settings → Accelerator → GPU, then Run all.')\n",
        "ver = m.group(1)\n",
        "if ver.startswith('12.6'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "elif ver.startswith('12.4'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu124','2.5.1','2.5.1','https://download.pytorch.org/whl/cu124')\n",
        "elif ver.startswith('12.'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "elif ver.startswith('11.8'):\n",
        "    fl, torch_ver, ta_ver, idx = ('cu118','2.1.2','2.1.2','https://download.pytorch.org/whl/cu118')\n",
        "else:\n",
        "    fl, torch_ver, ta_ver, idx = ('cu126','2.8.0','2.8.0','https://download.pytorch.org/whl/cu126')\n",
        "\n",
        "print('CUDA flavor:', fl)\n",
        "\n",
        "if mode == 'venv':\n",
        "    # Torch/torchaudio strictly from CUDA index inside venv\n",
        "    subprocess.check_call([py_exec, '-m', 'pip', 'install', '--extra-index-url', idx,\n",
        "                           f'torch=={torch_ver}+{fl}', f'torchaudio=={ta_ver}+{fl}'])\n",
        "    # Demucs and deps inside venv (no global bleed)\n",
        "    subprocess.check_call([py_exec, '-m', 'pip', 'install', 'demucs==4.0.1', 'torchcodec', 'ffmpeg-python', 'numpy==2.3.4'])\n",
        "    # Verify\n",
        "    subprocess.run([py_exec, '-c', \"import torch, demucs; print('Boot OK.', 'torch', torch.__version__, 'cuda', torch.cuda.is_available(), 'demucs', demucs.__version__)\"] , check=True)\n",
        "else:\n",
        "    # Target install into site_dir and use PYTHONPATH\n",
        "    subprocess.check_call([py_exec, '-m', 'pip', 'install', '--extra-index-url', idx,\n",
        "                           '--target', site_dir, f'torch=={torch_ver}+{fl}', f'torchaudio=={ta_ver}+{fl}'])\n",
        "    subprocess.check_call([py_exec, '-m', 'pip', 'install', '--target', site_dir,\n",
        "                           'demucs==4.0.1', 'torchcodec', 'ffmpeg-python', 'numpy==2.3.4'])\n",
        "    env = os.environ.copy()\n",
        "    env['PYTHONPATH'] = site_dir + (os.pathsep + env.get('PYTHONPATH',''))\n",
        "    subprocess.run([py_exec, '-c', \"import torch, demucs; import os; print('Boot OK.', 'torch', torch.__version__, 'cuda', torch.cuda.is_available(), 'demucs', demucs.__version__, 'mode', 'target')\"], check=True, env=env)\n",
        "\n",
        "# Persist run mode for next cell\n",
        "PMARK.write_text(json.dumps({'mode': mode, 'py': py_exec, 'site': site_dir, 'base': str(BASE)}))\n",
        "print('PY_MODE:', PMARK.read_text())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Launch watcher (Kaggle)\n",
        "import urllib.request, pathlib, os, json, subprocess\n",
        "BASE = pathlib.Path('/kaggle/working/M4L-Demucs')\n",
        "w = BASE/'colab_watcher.py'\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/VSTOPIA/Doctor-Sample-Unit-DSU/main/colab_watcher.py', w)\n",
        "print('Watcher saved to', w)\n",
        "\n",
        "# Load runtime mode from previous cell\n",
        "pmark = BASE/'PY_MODE.json'\n",
        "mode = 'venv'\n",
        "py_exec = 'python'\n",
        "site_dir = ''\n",
        "try:\n",
        "    data = json.loads(pmark.read_text())\n",
        "    mode = data.get('mode', 'venv')\n",
        "    py_exec = data.get('py', 'python')\n",
        "    site_dir = data.get('site', '')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "os.environ['DSU_ROOT'] = str(BASE)\n",
        "os.environ['DSU_REMOTE_JOBS_URL'] = 'https://raw.githubusercontent.com/VSTOPIA/Doctor-Sample-Unit-DSU/main/remote_jobs.jsonl'\n",
        "print('DSU_ROOT=', os.environ['DSU_ROOT'])\n",
        "print('DSU_REMOTE_JOBS_URL=', os.environ['DSU_REMOTE_JOBS_URL'])\n",
        "\n",
        "if mode == 'target' and site_dir:\n",
        "    env = os.environ.copy()\n",
        "    env['PYTHONPATH'] = site_dir + (os.pathsep + env.get('PYTHONPATH',''))\n",
        "    subprocess.call([py_exec, str(w)], env=env)\n",
        "else:\n",
        "    subprocess.call([py_exec, str(w)])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
